# homework 1

В этой ветке содержится решение 1-ой домашней работы по курсу "Глубокие генеративные модели".
Все использованные библиотеки указаны в `deep_gen_requirements_hw1.txt`

## MLE + Bayes для стилей и изображений

Файл deepgen_hw_1.ipynb содержит исходный код решения этой части ДЗ с комментариями. Для генерации всех возможных стилей и подсчета их вероятности использована функция styles_generator. Для выбора случайного стиля с учетом вероятностей используется функция `np.random.choice`. Пример стиля и его вероятности - ['прическа': 'короткая прямые',
  'цвет волос': 'пастельный розовый',
  'аксесуар': 'солнцезащитные очки',
  'одежда': 'комбинезон',
  'цвет одежды': 'розовый',
  'prob': 0.00027875905095346563]

Для генерации аватаров использованы изображения из основного репозитория курса. После подсчета вероятностей для каждого пикселя каждого канала происходит генерация 5 новых аватаров, примеры которых есть в файле deepgen_hw_1.ipynb `. Из-за высокого разрешения исходных изображений, получаемые отличаются лишь в отдельных пикселях, что почти незаметно для человеческого глаза.


## Автоэнкодер для детекции аномалий

Файл  deepgen_hw_1.ipynb  содержит исходный код решения этой части ДЗ. 

Задача заключается в детекции аномалий на изображениях лунок, в которые заливается металл для отливки изделий. В качестве базовой архитектуры сверточного автоэнкодера, которая обучалась с MSE со следующими параметрами:
- epoch = 50
- lr = 0.001
- img_size = (64, 64)


Оптимальный трешхолд, в первую очередь, зависит от бизнес-постановки (что для нас важнее - покрыть все, либо же минимизировать ложные срабатывания), в данном случае, был расчитан трешхолд через 95% процентиль всех анамолий, с таким трешхолдом получилось добиться следующих результатов:

Использованный трешхолд: 0.000013 \
True Positive Rate (Recall): 93.02% \
True Negative Rate: 50.89% \
Precision: 6.25% \
F1-score: 11.71% 

Матрица ошибок: \
TN: 1865 | FP: 1800 \
FN: 9 | TP: 120 

Как можно заметить, f-score очень низкий за счет очень низкого presicion. Далее был подобран трешхолд, который дал более качественные результаты:

Использованный трешхолд: 0.0001 \
True Positive Rate (Recall): 69.77% \
True Negative Rate: 98.74% \
Precision: 66.18% \
F1-score: 67.92% 

Матрица ошибок: \
TN: 3619 | FP: 46 \
FN: 39 | TP: 90 

В целом, достаточно адекватно для бейзлайна, но вот что еще в дальнейшем можно было бы улучшить:

* Улучшение архитктуру автоэнкодера, так как использовлаась базовая, например
* Увеличение глубины сети
* Добавление BatchNorm для стабилизации обучения
* Использование LeakyReLU вместо ReLU
* Dropout для регуляризации
